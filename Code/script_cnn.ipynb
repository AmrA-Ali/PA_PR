{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "39ab28e6-67b2-4129-9dbb-846c81ba85f2",
    "_uuid": "d00095bca1801c4058b75e706058a0651808596f"
   },
   "outputs": [],
   "source": [
    "# Change this to True to replicate the result\n",
    "COMPLETE_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5abea3ac-4fa5-4c4f-893f-7f2afa49e523",
    "_kg_hide-output": true,
    "_uuid": "337e0950ca948be32d5d881c1a3c675ccf7ac523"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97700e3e-82e1-4ce2-9da4-3f8f264e7558",
    "_kg_hide-output": true,
    "_uuid": "2ca1929548de57afb1c4fde19c10f7b18c64264e"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../freesound_lgbm/input/train.csv\")\n",
    "test = pd.read_csv(\"../freesound_lgbm/input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40b7ba05-45df-4779-be29-b177b9b9b8e1",
    "_uuid": "867f0074922314b78de6bd9d14b308b634d1fbbe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "train['nframes'] = train['fname'].apply(lambda f: wave.open('../freesound_lgbm/input/audio_train/' + f).getnframes())\n",
    "test['nframes'] = test['fname'].apply(lambda f: wave.open('../freesound_lgbm/input/audio_test/' + f).getnframes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58fbb75c-1ef8-478f-a5fd-3fe6cfda32af",
    "_kg_hide-output": true,
    "_uuid": "36454f818dcbe02852e7a639d428a004a387ce9f"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (Convolution1D, Dense, Dropout, GlobalAveragePooling1D, \n",
    "                          GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e0836104-1a4d-485d-9cc1-3e5b82f449de",
    "_uuid": "66640745984135b853d36eac127fb2da302319ad"
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f9d14e7d-89d8-42f0-9eb3-f895645b2de2",
    "_uuid": "aca30bc0f6fccf71e4b9a68e5c04c1aaf950b169"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, config, data_dir, list_IDs, labels=None, \n",
    "                 batch_size=64, preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def unpack_d(self):\n",
    "        return self.dim[0],self.dim[1]\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        X = np.empty((cur_batch_size, self.dim[0],self.dim[1]))#*self.dim))\n",
    "        #print(self.dim)\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n",
    "                                        res_type='kaiser_fast')\n",
    "\n",
    "            # Random offset / Padding\n",
    "            if len(data) > input_length:\n",
    "                max_offset = len(data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                data = data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(data):\n",
    "                    max_offset = input_length - len(data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "                \n",
    "            # Normalization + Other Preprocessing\n",
    "            if self.config.use_mfcc:\n",
    "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n",
    "                                                   n_mfcc=self.config.n_mfcc)\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "            else:\n",
    "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb5936dd-5fb1-4894-8165-6daf372a6832",
    "_uuid": "c9db10ad526815730a6e5a1f057de8c9bff12615"
   },
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3b9656b0-31d3-47ea-9bb3-789a40026793",
    "_uuid": "c2f0bbd810926b309d3b02473e937a2a86bc9005"
   },
   "source": [
    "* The dummy model is just for debugging purpose.\n",
    "* Our 1D Conv model is fairly deep and is trained using Adam Optimizer with a learning rate of 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "245887b3-a0dc-498d-900c-dd1c2898d955",
    "_uuid": "40771630994b93eee040c239f1c0e3bf88f13ced"
   },
   "outputs": [],
   "source": [
    "def get_1d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = GlobalMaxPool1D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def get_1d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e9027035-0e77-47dd-8616-113c1cfb37e0",
    "_uuid": "53aca10261dea0b8357e39adb513c7689b7c07ff"
   },
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2f2dc50-77d3-43ba-bf7f-3c6b39beb67b",
    "_uuid": "604a3c7971599898b5614a67da12da84ab651a55"
   },
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=100, audio_duration=1, n_folds=2, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e31b98ec-cecb-4584-9bbc-bc2748476b49",
    "_uuid": "7a2a5e44d82a2b9e04117b76464225278ec4a1d8"
   },
   "source": [
    "Here is the code for 10-fold training:\n",
    "* We use **`from sklearn.cross_validation.StratifiedKFold`** for splitting the trainig data into 10 folds.\n",
    "* We use some Keras callbacks to monitor the training.\n",
    "    * **`ModelCheckpoint`** saves the best weight of our model (using validation data). We use this weight to make test predictions.\n",
    "    * **`EarlyStopping`** stops the training once validation loss ceases to decrease\n",
    "    * **`TensorBoard`** helps us visualize training and validation loss and accuracy.\n",
    "* We fit the model using **`DataGenerator`** for training and validation splits. \n",
    "* We get both training and test predictions and save them as .npy format. We also generate a submission file. For 10-fold CV, the number of prediction files should be 10. We will ensemble these predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"predictions_1d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    train_set = train.iloc[train_split]\n",
    "    val_set = train.iloc[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"Fold: \", i)\n",
    "    print(\"#\"*50)\n",
    "    if COMPLETE_RUN:\n",
    "        model = get_1d_conv_model(config)\n",
    "    else:\n",
    "        model = get_1d_dummy_model(config)\n",
    "\n",
    "    train_generator = DataGenerator(config, '../freesound_lgbm/input/audio_train/', train_set.index, \n",
    "                                    train_set.label_idx, batch_size=64,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    val_generator = DataGenerator(config, '../freesound_lgbm/input/audio_train/', val_set.index, \n",
    "                                  val_set.label_idx, batch_size=64,\n",
    "                                  preprocessing_fn=audio_norm)\n",
    "\n",
    "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                  epochs=config.max_epochs, use_multiprocessing=True, workers=6, max_queue_size=20)\n",
    "\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    train_generator = DataGenerator(config, '../freesound_lgbm/input/audio_train/', train.index, batch_size=100,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose=1)\n",
    "    print(len(train_generator),len(predictions))\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    test_generator = DataGenerator(config, '../freesound_lgbm/input/audio_test/', test.index, batch_size=100,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose =1 )\n",
    "    print(len(train_generator),len(predictions))\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4050aede-678b-4f9e-bb95-e70f79e4f6bd",
    "_kg_hide-output": true,
    "_uuid": "bfdddecb92be07d06e71d25b1812d064a0cee66d"
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"input/freesound-prediction-file/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../freesound_lgbm/input/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"1d_conv_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dcb2a6e7-b086-4d1a-94a4-215f2cb101d0",
    "_uuid": "2f8dfd08f109ababeaca9ce900b68b8a716d28b7"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "SAMPLE_RATE = 44100\n",
    "fname = '../freesound_lgbm/input/audio_train/' + '00044347.wav'   # Hi-hat\n",
    "wav, _ = librosa.core.load(fname, sr=SAMPLE_RATE)\n",
    "wav = wav[:2*44100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6250242e-e3c5-4cb9-8405-43d3279dada1",
    "_kg_hide-output": true,
    "_uuid": "7498089442d866816aabc85234a8a5546c5e58da"
   },
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(wav, sr = SAMPLE_RATE, n_mfcc=40)\n",
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "384fe65d-fe10-4eee-826c-75c4dffcfa2d",
    "_kg_hide-output": true,
    "_uuid": "ed54039a4e0b91d10f603799feb8166404bbceec"
   },
   "outputs": [],
   "source": [
    "from keras.layers import (Convolution2D, GlobalAveragePooling2D, BatchNormalization, Flatten, AveragePooling2D,\n",
    "                          GlobalMaxPool2D, MaxPool2D, concatenate, Activation)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "97d07753-d78d-465d-936d-7f03eaf1def1",
    "_uuid": "0b2ac601f52ae4ed9dc849fcd095ab94cfe878fe"
   },
   "outputs": [],
   "source": [
    "def get_2d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = GlobalMaxPool2D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_2d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    \n",
    "    inp = Input(shape=(config.dim[0],config.dim[1],1))\n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPool2D()(x)\n",
    "    \n",
    "    x = Convolution2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0c823de-9971-4247-9501-dc74d2f95d8e",
    "_uuid": "d88e90fdc36c77c10ecc8f674d6fd39c8e4d78fb"
   },
   "source": [
    "<a id=\"2d_data\"></a>\n",
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "eb5aef7d-669b-4cde-9e09-a2bfaa379cc9",
    "_uuid": "70b8cd145ae3838c7974fe257403c8c7fbc8552a"
   },
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=44100, audio_duration=2, n_folds=10, \n",
    "                learning_rate=0.0001, use_mfcc=True, n_mfcc=40)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=44100, audio_duration=2, n_folds=2, \n",
    "                    max_epochs=1, use_mfcc=True, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b9b1c9b-7e02-46f3-96f6-67ebc9bf9132",
    "_uuid": "5242e943f1bc1154d19c03c361a826553c811cfe"
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "    input_length = config.audio_length\n",
    "    icn = 0\n",
    "    for i, fname in enumerate(df.index):\n",
    "        icn+=1\n",
    "        #print fname\n",
    "        file_path = data_dir + fname\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "        data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        X[i,] = data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print train.index\n",
    "test = pd.read_csv('../freesound_lgbm/input/sample_submission.csv')\n",
    "train = pd.read_csv('../freesound_lgbm/input/train.csv')\n",
    "\n",
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = prepare_data(train, config, '../freesound_lgbm/input/audio_train/')\n",
    "X_test = prepare_data(test, config, '../freesound_lgbm/input/audio_test/')\n",
    "y_train = to_categorical(train.label_idx, num_classes=config.n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0e0b17b-d2f8-47f8-9b4d-fff3b2761dde",
    "_uuid": "89e8bd3dc6d1f432309e668685fb98d1ce866e95"
   },
   "source": [
    "<a id=\"2d_normalization\"></a>\n",
    "#### Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af8afd09-66bf-4618-ad95-d70db35b90ec",
    "_uuid": "b70fea949114595111c39f9f64fb1752603e3fdf"
   },
   "source": [
    "<a id=\"2d_training\"></a>\n",
    "#### Training 2D Conv on MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"predictions_2d_conv_lr0.0001_avgpool\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    K.clear_session()\n",
    "    X, y, X_val, y_val = X_train[train_split], y_train[train_split], X_train[val_split], y_train[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%i'%i, write_graph=True)\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"#\"*50)\n",
    "    print(\"Fold: \", i)\n",
    "    model = get_2d_conv_model(config)\n",
    "    history = model.fit(X, y, validation_data=(X_val, y_val), callbacks=callbacks_list, \n",
    "                        batch_size=50, epochs=config.max_epochs)\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    predictions = model.predict(X_train, batch_size=50, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    predictions = model.predict(X_test, batch_size=50, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c253178-6cde-4bad-835d-d09484f381ed",
    "_uuid": "e6868eb538b9fed874fcb02183d2edd348d38b5f"
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "#for i in range(10):\n",
    "    #pred_list.append(np.load(\"input/freesound-prediction-data-2d-conv-reduced-lr/test_predictions_%d.npy\"%i))\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../freesound_lgbm/input/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"2d_conv_lr0005_drpout025_ensembled_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
