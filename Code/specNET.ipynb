{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import optimizers, applications, regularizers\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,core\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D,Conv1D, MaxPooling2D\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 299,299\n",
    "train_data_dir = 'train/'\n",
    "validation_data_dir = 'validation/'\n",
    "test_data_dir = 'test/'\n",
    "nb_train_samples = 7105 \n",
    "nb_validation_samples =  2368\n",
    "epochs = 600 \n",
    "batch_size = 4\n",
    "num_classes = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(img_width, img_height, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "#model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
    "base_model = applications.Xception(input_tensor=input_tensor,pooling = 'avg', include_top=False,weights=None)\n",
    "\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dropout(0.8)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        width_shift_range = 0.8,\n",
    "        horizontal_flip = True,\n",
    "        fill_mode = 'reflect'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = True)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.004, momentum=0.9,decay = 1e-6, nesterov = True)\n",
    "\n",
    "#model.compile(optimizer='adadelta', loss='categorical_hinge', metrics=['accuracy'])\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('logs/' + 'weights-{epoch:02d}-{val_acc:.2f}-{val_loss:.2f}.h5',\n",
    "                                monitor='val_loss',save_best_only=True, save_weights_only=True, verbose=1)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('logs/weights-22-0.66-1.28.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'test/',\n",
    "        target_size=(img_width,img_height),\n",
    "        batch_size=4,\n",
    "        class_mode=None,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results = model.predict_generator(\n",
    "                             validation_generator, \n",
    "                             steps = 2368 // batch_size)\n",
    "val_eval = model.evaluate_generator(\n",
    "                             validation_generator, \n",
    "                             steps = 2368 // batch_size)\n",
    "print(val_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.predict_generator(\n",
    "                             test_generator, \n",
    "                             steps = 9400 // batch_size,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [list(np.argsort(test_results[i])[::-1][:3]) for i in range(len(test_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_to_labels(p, labels):\n",
    "    predictions = [list(np.argsort(p[i])[::-1][:3]) for i in range(len(p))]\n",
    "    prediction_labels = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        label_list = []\n",
    "        for output in pred:\n",
    "            label_list.append(labels[output])\n",
    "        prediction_labels.append(label_list)\n",
    "    return prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indi = train_generator.class_indices\n",
    "labels = [' ']*41\n",
    "for e in indi:\n",
    "    labels[indi[e]] = e\n",
    "    \n",
    "predi = preds_to_labels(test_results,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def create_submission(predictions, name='submission.csv'):\n",
    "    predictions = ['{} {} {}'.format(x[0], x[1], x[2]) for x in predictions]\n",
    "    submission = pd.read_csv('../freesound_lgbm/input/sample_submission.csv')\n",
    "    submission.label = predictions\n",
    "    submission.to_csv('{}'.format(name), index=False)\n",
    "    print(\"Submission saved to '{}'\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(predi,name='tryout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [list(np.argsort(test_results[i])[::-1][:3]) for i in range(len(test_results))]\n",
    "actual = [[i] for i in y_valid]\n",
    "valid_score = mapk(actual, predictions, k=3)\n",
    "\n",
    "print(valid_score)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
